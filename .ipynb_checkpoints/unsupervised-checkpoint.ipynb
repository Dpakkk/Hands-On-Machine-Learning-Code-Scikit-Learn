{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22213541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised has no known output, no teacher to instruct the learning algorithm\n",
    "# Upsupervised learning algorithm: clusturing and data transformation\n",
    "# common unsupervised algorithm is dimensionality reduction - high dimension data (many feature data) to find new way of dat a\n",
    "# that summarizes essential characteristics of data\n",
    "# upsupervised alrogithms is mostly used as a data preprocessing part in supervised algorithms\n",
    "\n",
    "#Learning new way of representing data can help supervised algorithm to increase accuracy, reduce memory and time consumption\n",
    "# pre processing methods like scaling method are usually applied before applying supervised algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f419cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of scaling in breast cancer dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e0b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for the size before scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264ca43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ca8f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9210936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "scale.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87ed2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points\n",
    "# to actually scale the training data, we use transform method of the scaler\n",
    "# the transform method is used in scikit learn whenever model returns a new representation of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fe494d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scale.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc06f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed shape:(426, 30)\n",
      "per-feature min value before scaling:\n",
      "[6.981e+00 9.710e+00 4.379e+01 1.435e+02 5.263e-02 1.938e-02 0.000e+00\n",
      " 0.000e+00 1.060e-01 5.024e-02 1.153e-01 3.602e-01 7.570e-01 6.802e+00\n",
      " 1.713e-03 2.252e-03 0.000e+00 0.000e+00 9.539e-03 8.948e-04 7.930e+00\n",
      " 1.202e+01 5.041e+01 1.852e+02 7.117e-02 2.729e-02 0.000e+00 0.000e+00\n",
      " 1.566e-01 5.521e-02]\n",
      "per-feature max value before scaling:\n",
      "[2.811e+01 3.928e+01 1.885e+02 2.501e+03 1.634e-01 2.867e-01 4.268e-01\n",
      " 2.012e-01 3.040e-01 9.575e-02 2.873e+00 4.885e+00 2.198e+01 5.422e+02\n",
      " 3.113e-02 1.354e-01 3.960e-01 5.279e-02 6.146e-02 2.984e-02 3.604e+01\n",
      " 4.954e+01 2.512e+02 4.254e+03 2.226e-01 9.379e-01 1.170e+00 2.910e-01\n",
      " 5.774e-01 1.486e-01]\n",
      "per-feature min value after scaling:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "per-feature max value after scaling:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# printing dataset properties before and after scaling\n",
    "print(\"transformed shape:{}\".format(X_train_scaled.shape))\n",
    "print(\"per-feature min value before scaling:\\n{}\".format(X_train.min(axis = 0)))\n",
    "print(\"per-feature max value before scaling:\\n{}\".format(X_train.max(axis = 0)))\n",
    "\n",
    "print(\"per-feature min value after scaling:\\n{}\".format(X_train_scaled.min(axis = 0)))\n",
    "print(\"per-feature max value after scaling:\\n{}\".format(X_train_scaled.max(axis = 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aabbc6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-feature min values:\n",
      "[ 0.0336031   0.0226581   0.03144219  0.01141039  0.14128374  0.04406704\n",
      "  0.          0.          0.1540404  -0.00615249 -0.00137796  0.00594501\n",
      "  0.00430665  0.00079567  0.03919502  0.0112206   0.          0.\n",
      " -0.03191387  0.00664013  0.02660975  0.05810235  0.02031974  0.00943767\n",
      "  0.1094235   0.02637792  0.          0.         -0.00023764 -0.00182032]\n",
      "per-feature max values:\n",
      "[0.9578778  0.81501522 0.95577362 0.89353128 0.81132075 1.21958701\n",
      " 0.87956888 0.9333996  0.93232323 1.0371347  0.42669616 0.49765736\n",
      " 0.44117231 0.28371044 0.48703131 0.73863671 0.76717172 0.62928585\n",
      " 1.33685792 0.39057253 0.89612238 0.79317697 0.84859804 0.74488793\n",
      " 0.9154725  1.13188961 1.07008547 0.92371134 1.20532319 1.63068851]\n"
     ]
    }
   ],
   "source": [
    "# transforming testin dataset as well\n",
    "X_test_scale = scale.transform(X_test)\n",
    "\n",
    "print(\"per-feature min values:\\n{}\".format(X_test_scale.min(axis = 0)))\n",
    "print(\"per-feature max values:\\n{}\".format(X_test_scale.max(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c508fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the surprise here is we didnt get 0 and 1 in testing dataset\n",
    "# the reason behid this is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3950de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the confusion between fit and transform in dataset\n",
    "# Same Scaling should be done in training and testing dataset\n",
    "# Shortcut and Efficient Alternatives\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# calling fit and transform in sequence (using method chaining)\n",
    "X_scaled = scaler.fit(X).transform(X)\n",
    "\n",
    "# same result, but more efficient computation\n",
    "x_scaled_efficient = scaler.fit_transform(X)\n",
    "\n",
    "# Lets assume we extract sample X from the dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4cde7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
